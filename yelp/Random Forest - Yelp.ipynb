{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Hyper Parameter Setting\n",
    "\n",
    "The kernel is restarted every time the parameters are changed to make reproducibility easier. \n",
    "\n",
    "#### The Pretrained Model\n",
    "\n",
    "The first few blocks format the data and create the training and validation split. These bloack up until the section on hyper parameters must be run. Then under the 'loading the model' section the last block should be run. This block is entitled load model. In the 'Final model' section the last block, entitled 'accuracy rates' can be run. This will run the model on the preprocessed data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# look into preprocessor.py file for details\n",
    "from preprocessor import DocumentTermMatrix, accuracy, indicator_to_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yelp_data = DocumentTermMatrix(\"yelp_academic_dataset_review.json\", \"text\", \"stars\", 1000) #  TDM with IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = len(yelp_data.docs_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "# data split - training and validation data (80, 20)\n",
    "X_train, X_test,Y_train, Y_test = cross_validation.train_test_split(yelp_data.X_docs,yelp_data.Y_docs,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter \n",
    "\n",
    "The code in this section is specifically for setting hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Building model...', 0)\n",
      "('Building model...', 1)\n",
      "('Building model...', 2)\n",
      "('Building model...', 3)\n"
     ]
    }
   ],
   "source": [
    "models = ['' for i in xrange(4)] \n",
    "for cv in xrange(4):\n",
    "    \n",
    "    print('Building model...', cv)\n",
    "    models[cv] = RandomForestClassifier(10,max_features=\"log2\") # 1000 as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from preprocessor import Kfold_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_index = [i for i in xrange(len(X_train))]\n",
    " \n",
    "indices_cv = Kfold_cv(full_index,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "histories = []\n",
    "\n",
    "out_sample_accuracies = []\n",
    "in_sample_accuracies = []\n",
    "\n",
    "for cv in xrange(4):\n",
    "    np.random.seed(1337)  # for reproducibility\n",
    "    # data split\n",
    "    #  this could be done in a single shot before hand\n",
    "    #  at the moment this will preserve memory which seems import in a VM setting\n",
    "    x_train = X_train[indices_cv[cv][\"train\"]] \n",
    "    x_test  = X_train[indices_cv[cv][\"test\"]] \n",
    "\n",
    "    y_train = [ lang_data.docs_label_index[Y_train[i]] for i in indices_cv[cv][\"train\"] ] \n",
    "    y_test  = [ lang_data.docs_label_index[Y_train[i]] for i in indices_cv[cv][\"test\"] ] \n",
    "\n",
    "    # create appropirate matrix (hot encoded) response\n",
    "    # y_train, y_test = [indicator_to_matrix(x,lang_data.docs_label_index)  for x in (y_train, y_test)]\n",
    "\n",
    "    history = models[cv].fit(x_train, y_train) \n",
    "    \n",
    "    # set validation split to 0 or none so all the traning data is used \n",
    "    #   the out of sample rate will be determined later\n",
    "\n",
    "    # do not set verbose = 1\n",
    "    \n",
    "    train_pred = models[cv].predict(x_train)\n",
    "    test_pred = models[cv].predict(x_test)\n",
    "    \n",
    "    train_acc = 100*float(np.array([ train_pred[idx] == y_train[idx]  for idx, pred in enumerate(train_pred)]).sum())/len(train_pred)\n",
    "    test_acc  = 100*float(np.array([ test_pred[idx]  == y_test[idx]   for idx, pred in enumerate(test_pred )]).sum())/len(test_pred )\n",
    "    \n",
    "    out_sample_accuracies.append(test_acc)\n",
    "    in_sample_accuracies.append(train_acc)\n",
    "    \n",
    "    histories.append(history) # don't know how kosher this is, seems worth trying though :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[99.758454106280197, 95.652173913043484]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.mean(in_sample_accuracies),np.mean(out_sample_accuracies)]\n",
    "\n",
    "# log2, sqrt, num_trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model\n",
    "\n",
    "The code in this section is for the final model.\n",
    "\n",
    "The Kernel should be reset before running the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(100,max_features=\"log2\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1337)  # for reproducibility\n",
    "    \n",
    "y_train = [ yelp_data.docs_label_index[i] for i in Y_train ] \n",
    "y_test  = [ yelp_data.docs_label_index[i] for i in Y_test ] \n",
    "\n",
    "# create appropirate matrix (hot encoded) response\n",
    "# y_train, y_test = [indicator_to_matrix(x,lang_data.docs_label_index)  for x in (y_train, y_test)]\n",
    "\n",
    "history = model.fit(X_train, y_train) \n",
    "    \n",
    "# set validation split to 0 or none so all the traning data is used \n",
    "#   the out of sample rate will be determined later\n",
    "\n",
    "# do not set verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 43.0]\n"
     ]
    }
   ],
   "source": [
    "# accuracy rates\n",
    "\n",
    "y_train = [ yelp_data.docs_label_index[i] for i in Y_train ] \n",
    "y_test  = [ yelp_data.docs_label_index[i] for i in Y_test ] \n",
    "\n",
    "train_pred = model.predict(X_train)\n",
    "test_pred  = model.predict(X_test)\n",
    "    \n",
    "train_acc = 100*float(np.array([ train_pred[idx] == y_train[idx]  for idx, pred in enumerate(train_pred)]).sum())/len(train_pred)\n",
    "test_acc  = 100*float(np.array([ test_pred[idx]  == y_test[idx]   for idx, pred in enumerate(test_pred )]).sum())/len(test_pred )\n",
    "\n",
    "print([train_acc,test_acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "import cPickle\n",
    "# save the classifier\n",
    "with open('yelp_rf.pkl', 'wb') as fid:\n",
    "    cPickle.dump(model, fid)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "import cPickle\n",
    "with open('yelp_rf.pkl', 'rb') as fid:\n",
    "    model = cPickle.load(fid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
